# Poker-Neural-Network

Neural Networks in the past, such as Alpha Go and Deep Blue who beat the top players in their respective games (Go and Chess), were fully trained using “human played games” in their database and learning form that. Alpha Go was defeated by its predecessor, Alpha Zero, which did not learn to play Go using human played games, but rather, playing again different versions of itself and learning from its own mistakes.

This is the goal for the project; To be able to let the Neural Network train by itself without any human intervention and for it to be able to not only play at a human level, but far exceed human level capabilities. The Neural Network will be allowed to see only a limited number of inputs, as being able to see the entire deck at one time would make it too easy to know what the other player has. Instead the network would be given data such as, its own hand (2 cards), the center Cards (3 cards, then 1 card, then 1 card), the pot size, how many chips it has, how many chips that the opponent has, and what the previous bets were. This information that we would be giving to the Neural Network would be the exact same information a human would have access to in a real game and nothing more. We are not giving the Neural Network any special privileges. We want it to be a fair playing field when it faces its human challengers. Other than its super human training speeds, where a normal human would take years to master the game, the Neural Network ay only need a few days or even hours, we want the Neural Network to have the same resources that any human, whether they are a casual poker player or a poker campion, and then to come out on top.
